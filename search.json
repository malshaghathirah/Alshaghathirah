[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Mohammed Alshaghathirah",
    "section": "",
    "text": "Hello! I‚Äôm Mohammed Alshaghathirah, a graduate student pursuing a Master of Quantitative Finance at UC San Diego.\nI have a strong background in procurement, sales, and administrative coordination, with experience across both the retail and e-commerce sectors. I‚Äôm passionate about financial data analysis, business operations, and using technology to drive smart decision-making.\n\n\n\n\n\nSeptember 2015 ‚Äì September 2017\n- Helped organize events including Saudi National Day.\n- Led a team of Saudi students at international festivals.\n\n\n\nApril 2020 ‚Äì January 2023\n- Managed advertising campaigns through social media.\n- Built strong supplier and customer relationships.\n- Analyzed marketing and merchandising performance.\n- Sold coffee to local coffee shops and restaurants.\n- Sourced products and negotiated supplier deals.\n\n\n\nJanuary 2023 ‚Äì September 2024\n- Oversaw full supply chain operations.\n- Ensured timely flow of goods from suppliers to retailers.\n- Managed sales department operations.\n- Handled food redistribution to markets and hypermarkets.\n\n\n\n\n\n\nNative Arabic\n\nFluent English\n\n\n\n\n\n\nMS Office, Google Drive, Email\n\nData Analysis, Time Management\n\nProblem-Solving, Communication\n\n\n\n\n\n\nHomework 1: Matching Donations Replication"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Mohammed Alshaghathirah",
    "section": "",
    "text": "September 2015 ‚Äì September 2017\n- Helped organize events including Saudi National Day.\n- Led a team of Saudi students at international festivals.\n\n\n\nApril 2020 ‚Äì January 2023\n- Managed advertising campaigns through social media.\n- Built strong supplier and customer relationships.\n- Analyzed marketing and merchandising performance.\n- Sold coffee to local coffee shops and restaurants.\n- Sourced products and negotiated supplier deals.\n\n\n\nJanuary 2023 ‚Äì September 2024\n- Oversaw full supply chain operations.\n- Ensured timely flow of goods from suppliers to retailers.\n- Managed sales department operations.\n- Handled food redistribution to markets and hypermarkets."
  },
  {
    "objectID": "index.html#languages",
    "href": "index.html#languages",
    "title": "Mohammed Alshaghathirah",
    "section": "",
    "text": "Native Arabic\n\nFluent English"
  },
  {
    "objectID": "index.html#skills",
    "href": "index.html#skills",
    "title": "Mohammed Alshaghathirah",
    "section": "",
    "text": "MS Office, Google Drive, Email\n\nData Analysis, Time Management\n\nProblem-Solving, Communication"
  },
  {
    "objectID": "index.html#homework-pages",
    "href": "index.html#homework-pages",
    "title": "Mohammed Alshaghathirah",
    "section": "",
    "text": "Homework 1: Matching Donations Replication"
  },
  {
    "objectID": "homework2.html",
    "href": "homework2.html",
    "title": "Homework 2",
    "section": "",
    "text": "Homework 2: Poisson Regression & MLE\nüëâ Click here to view the full blog post"
  },
  {
    "objectID": "homework4.html",
    "href": "homework4.html",
    "title": "Homework 4: Machine Learning Applications in Marketing",
    "section": "",
    "text": "title: ‚ÄúHomework 4‚Äù format: html page-layout: article ‚Äî\n\nHomework 4: Machine Learning Applications in Marketing\nüëâ Click here to view the full blog post"
  },
  {
    "objectID": "homework1.html",
    "href": "homework1.html",
    "title": "Homework 1",
    "section": "",
    "text": "Homework 1\nHere is my analysis for Homework 1.\nüëâ Click here to view the full blog post"
  },
  {
    "objectID": "homework3.html",
    "href": "homework3.html",
    "title": "Homework 3: Multinomial Logit Model",
    "section": "",
    "text": "title: ‚ÄúHomework 3‚Äù format: html page-layout: article ‚Äî\n\nHomework 3: Multinomial Logit Model\nüëâ Click here to view the full blog post"
  },
  {
    "objectID": "homework 3.html",
    "href": "homework 3.html",
    "title": "Multinomial Logit Model",
    "section": "",
    "text": "Author: Mohammed Alshaghathirah\nDate: May 28, 2025"
  },
  {
    "objectID": "homework 3.html#introduction",
    "href": "homework 3.html#introduction",
    "title": "Multinomial Logit Model",
    "section": "Introduction",
    "text": "Introduction\nUnderstanding how consumers make choices between competing products is a central question in marketing analytics. One widely used approach to modeling such decisions is conjoint analysis, which helps us infer preferences based on observed choices among different product configurations. In this assignment, we analyze simulated conjoint data using the Multinomial Logit Model (MNL) ‚Äî a powerful tool for modeling discrete choices.\nThe MNL model assumes that each consumer chooses the product that provides the highest utility, where utility is a function of observable product attributes (e.g., brand, advertising, price) and a random error term. This framework enables us to estimate how much each attribute contributes to consumer preferences.\nOur analysis proceeds in two main parts:\n\nMaximum Likelihood Estimation (MLE) ‚Äî We estimate the model by finding the parameters that maximize the likelihood of observing the choices in our data.\nBayesian Estimation using Metropolis-Hastings MCMC ‚Äî We apply a Bayesian approach to estimate the posterior distribution of the parameters, allowing for uncertainty quantification and comparison with the MLE results.\n\nThe goal is not only to estimate consumer preferences but also to interpret the results in a meaningful, business-relevant context."
  },
  {
    "objectID": "homework 3.html#likelihood-for-the-multinomial-logit-mnl-model",
    "href": "homework 3.html#likelihood-for-the-multinomial-logit-mnl-model",
    "title": "Multinomial Logit Model",
    "section": "1. Likelihood for the Multinomial Logit (MNL) Model",
    "text": "1. Likelihood for the Multinomial Logit (MNL) Model\nWe assume each consumer selects one product from a set of alternatives. The utility that consumer ( i ) derives from product ( j ) is:\n\\[\nU_{ij} = x_j' \\beta + \\epsilon_{ij}\n\\]\nwhere: - ( x_j ) is a vector of product attributes (e.g., brand, ad, price), - ( ) is a vector of coefficients (part-worth utilities), - ( _{ij} (0, 1) )\nThis leads to the well-known logit choice probability:\n\\[\n\\mathbb{P}_i(j) = \\frac{e^{x_j' \\beta}}{\\sum_{k=1}^J e^{x_k' \\beta}}\n\\]\nThis closed-form solution allows us to estimate ( ) using maximum likelihood or Bayesian methods."
  },
  {
    "objectID": "homework 3.html#structure-of-the-simulated-dataset",
    "href": "homework 3.html#structure-of-the-simulated-dataset",
    "title": "Multinomial Logit Model",
    "section": "2. Structure of the Simulated Dataset",
    "text": "2. Structure of the Simulated Dataset\nBefore estimating the Multinomial Logit model, we begin by exploring the structure of the conjoint dataset.\nEach row in the dataset corresponds to a product profile evaluated by a respondent in a choice task. The dataset includes the following variables:\n\nresp: Respondent ID\ntask: Choice task number\nchoice: Indicator variable (1 if the product was chosen, 0 otherwise)\nbrand: Product brand (categorical: N, H, P)\nad: Whether the product had advertising support (Yes or No)\nprice: Price of the product\n\nWe load the data and display the first few rows:\n\nimport pandas as pd\n\n\nconjoint = pd.read_csv(\"/content/conjoint_data.csv\")\n\n\nconjoint.head()\n\n\n    \n\n\n\n\n\n\nresp\ntask\nchoice\nbrand\nad\nprice\n\n\n\n\n0\n1\n1\n1\nN\nYes\n28\n\n\n1\n1\n1\n0\nH\nYes\n16\n\n\n2\n1\n1\n0\nP\nYes\n16\n\n\n3\n1\n2\n0\nN\nYes\n32\n\n\n4\n1\n2\n1\nP\nYes\n16\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n    \n  \n\n\nThe dataset preview above shows the structure of our conjoint experiment data. Each row represents a specific product profile shown to a respondent during a choice task.\n\nIn the first task (task = 1) for resp = 1, the respondent was shown three alternatives (brand = N, H, P) and chose the product from brand N (choice = 1).\nIn the second task (task = 2), the same respondent chose the product from brand P.\n\nEach product is defined by its brand, whether it had advertising (ad), and its price. This structure will be key for estimating the utility values associated with each attribute using a Multinomial Logit model.\nWe can also check basic summary statistics and the number of respondents and tasks:\n\n\nconjoint.describe()\n\n\nprint(\"Unique respondents:\", conjoint['resp'].nunique())\nprint(\"Unique tasks per respondent:\", conjoint.groupby('resp')['task'].nunique().mean())\nprint(\"Unique brands:\", conjoint['brand'].unique())\n\nUnique respondents: 100\nUnique tasks per respondent: 10.0\nUnique brands: ['N' 'H' 'P']\n\n\nFrom our summary inspection, we observe the following about the dataset:\n\nThere are 100 unique respondents, each participating in the experiment.\nEach respondent completed exactly 10 choice tasks.\nIn each task, they evaluated and selected among 3 product alternatives.\nThe product options span 3 different brands: 'N', 'H', and 'P'.\n\nThis balanced panel structure ‚Äî where all respondents evaluate the same number of tasks with consistent product configurations ‚Äî makes the data well-suited for estimating a Multinomial Logit model."
  },
  {
    "objectID": "homework 3.html#estimating-the-mnl-model-via-maximum-likelihood",
    "href": "homework 3.html#estimating-the-mnl-model-via-maximum-likelihood",
    "title": "Multinomial Logit Model",
    "section": "3. Estimating the MNL Model via Maximum Likelihood",
    "text": "3. Estimating the MNL Model via Maximum Likelihood\nWe begin by estimating the parameters of the Multinomial Logit model using Maximum Likelihood Estimation (MLE). The utility that respondent ( i ) derives from alternative ( j ) in task ( t ) is modeled as:\n\\[\nU_{ijt} = x_{ijt}' \\beta + \\epsilon_{ijt}\n\\]\nwhere: - ( x_{ijt} ) includes product attributes such as brand, ad exposure, and price, - ( ) is a vector of coefficients (part-worth utilities), - ( _{ijt} (0, 1) ).\nThe probability that a consumer chooses alternative ( j ) is given by:\n\\[\n\\mathbb{P}_{ijt} = \\frac{e^{x_{ijt}' \\beta}}{\\sum_{k=1}^{J} e^{x_{ikt}' \\beta}}\n\\]\nWe now implement the log-likelihood function and use numerical optimization to estimate ( ).\n\nimport pandas as pd\nimport numpy as np\nfrom scipy.optimize import minimize\n\n\nconjoint = pd.read_csv(\"/content/conjoint_data.csv\")\n\n\nconjoint_encoded = pd.get_dummies(conjoint, columns=['brand', 'ad'], drop_first=False)\n\n\nX = conjoint_encoded[['brand_H', 'brand_P', 'ad_Yes', 'price']].astype(np.float64).values\ny = conjoint_encoded['choice'].astype(np.int32).values\ngroups = conjoint_encoded.groupby(['resp', 'task']).ngroup()\n\n\ndef neg_log_likelihood(beta):\n    beta = np.asarray(beta, dtype=np.float64)\n    utilities = X @ beta\n    exp_utilities = np.exp(utilities)\n\n    probs = np.zeros_like(exp_utilities)\n    for g in np.unique(groups):\n        mask = (groups == g)\n        denom = np.sum(exp_utilities[mask])\n        probs[mask] = exp_utilities[mask] / denom\n\n    log_likelihood = np.sum(np.log(probs[y == 1]))\n    return -log_likelihood\n\n\ninitial_beta = np.zeros(X.shape[1], dtype=np.float64)\n\n\nresult = minimize(neg_log_likelihood, initial_beta, method='BFGS')\n\n\nestimated_betas = pd.Series(result.x, index=['brand_H', 'brand_P', 'ad_Yes', 'price'])\nprint(estimated_betas)\n\n\n\n\n\nbrand_H   -0.941195\nbrand_P   -0.439579\nad_Yes    -0.731994\nprice     -0.099480\ndtype: float64"
  },
  {
    "objectID": "homework 3.html#estimating-the-mnl-model-via-maximum-likelihood-1",
    "href": "homework 3.html#estimating-the-mnl-model-via-maximum-likelihood-1",
    "title": "Multinomial Logit Model",
    "section": "3. Estimating the MNL Model via Maximum Likelihood",
    "text": "3. Estimating the MNL Model via Maximum Likelihood\nWe estimated the parameters of the Multinomial Logit (MNL) model using maximum likelihood. The utility specification includes brand, advertisement exposure, and price. We treat brand_N and ad_No as baseline categories by omitting them from the regression.\n\nEstimated Coefficients:\n\n\n\nVariable\nEstimate\n\n\n\n\nbrand_H\n-0.9412\n\n\nbrand_P\n-0.4396\n\n\nad_Yes\n-0.7320\n\n\nprice\n-0.0995\n\n\n\n\n\nInterpretation:\n\nBoth brand_H and brand_P are less preferred than the baseline brand (brand_N). In particular, brand_H is significantly less preferred.\nThe negative coefficient on ad_Yes suggests that advertising had a negative effect on utility. This could reflect poor ad quality or overexposure.\nThe price coefficient is negative, consistent with economic intuition: as price increases, the probability of choice decreases.\n\nWe now move on to estimate the same model using Bayesian methods, which allows us to quantify uncertainty more explicitly."
  },
  {
    "objectID": "homework 3.html#bayesian-estimation-using-metropolis-hastings",
    "href": "homework 3.html#bayesian-estimation-using-metropolis-hastings",
    "title": "Multinomial Logit Model",
    "section": "4. Bayesian Estimation using Metropolis-Hastings",
    "text": "4. Bayesian Estimation using Metropolis-Hastings\nTo complement the MLE approach, we estimate the Multinomial Logit model using a Bayesian framework. We use the Metropolis-Hastings (MH) algorithm to sample from the posterior distribution of the coefficients.\nWe assume independent Normal(0, 1) priors for each parameter:\n\\[\n\\beta_k \\sim \\mathcal{N}(0, 1)\n\\]\nThe log-posterior is given by:\n\\[\n\\log P(\\beta \\mid \\text{data}) \\propto \\log \\mathcal{L}(\\beta) + \\log \\mathcal{P}(\\beta)\n\\]\nWhere ( () ) is the likelihood function and ( () ) is the prior.\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n\n\ndef log_prior(beta):\n    return -0.5 * np.sum(beta**2)\n\ndef log_likelihood(beta):\n    utilities = X @ beta\n    exp_utilities = np.exp(utilities)\n\n    probs = np.zeros_like(exp_utilities)\n    for g in np.unique(groups):\n        mask = (groups == g)\n        denom = exp_utilities[mask].sum()\n        probs[mask] = exp_utilities[mask] / denom\n\n    return np.sum(np.log(probs[y == 1]))\n\ndef log_posterior(beta):\n    return log_likelihood(beta) + log_prior(beta)\n\ndef fast_mh_sampler(log_post, initial, steps=1000, proposal_scale=0.1):\n    beta = np.array(initial)\n    samples = []\n    accepted = 0\n\n    for _ in range(steps):\n        proposal = beta + np.random.normal(0, proposal_scale, size=beta.shape)\n        lp_current = log_post(beta)\n        lp_proposal = log_post(proposal)\n\n        accept_ratio = np.exp(lp_proposal - lp_current)\n        if np.random.rand() &lt; min(1, accept_ratio):\n            beta = proposal\n            accepted += 1\n        samples.append(beta.copy())\n\n    print(f\"Acceptance Rate: {accepted / steps:.2f}\")\n    return np.array(samples)\n\n\ninitial_beta = np.zeros(X.shape[1])\nsamples_fast = fast_mh_sampler(log_posterior, initial_beta, steps=1000, proposal_scale=0.15)\n\n\nposterior_means_fast = pd.Series(np.mean(samples_fast[500:], axis=0), index=['brand_H', 'brand_P', 'ad_Yes', 'price'])\nprint(posterior_means_fast)\n\n\nAcceptance Rate: 0.02\nbrand_H   -0.987987\nbrand_P   -0.495108\nad_Yes    -0.676342\nprice     -0.097416\ndtype: float64"
  },
  {
    "objectID": "homework 3.html#bayesian-estimation-using-metropolis-hastings-1",
    "href": "homework 3.html#bayesian-estimation-using-metropolis-hastings-1",
    "title": "Multinomial Logit Model",
    "section": "4. Bayesian Estimation using Metropolis-Hastings",
    "text": "4. Bayesian Estimation using Metropolis-Hastings\nWe estimated the parameters of the Multinomial Logit model using a Bayesian approach via the Metropolis-Hastings algorithm. Each coefficient was given a Normal(0, 1) prior, and we used 1,000 sampling steps with a moderate proposal width.\nAlthough the acceptance rate was relatively low (2%), the chain still explored the posterior distribution and provided stable estimates.\n\nPosterior Mean Estimates\n\n\n\nVariable\nPosterior Mean\n\n\n\n\nbrand_H\n-0.988\n\n\nbrand_P\n-0.495\n\n\nad_Yes\n-0.676\n\n\nprice\n-0.097\n\n\n\nThese results are consistent with our MLE estimates from Section 3, reaffirming the conclusion that consumers disfavor brands H and P compared to the base brand N. Ads had a small negative effect, and price negatively impacted choice probability."
  },
  {
    "objectID": "homework 3.html#comparing-mle-and-bayesian-estimates",
    "href": "homework 3.html#comparing-mle-and-bayesian-estimates",
    "title": "Multinomial Logit Model",
    "section": "5. Comparing MLE and Bayesian Estimates",
    "text": "5. Comparing MLE and Bayesian Estimates\nBelow we compare the coefficients estimated using Maximum Likelihood Estimation (MLE) and Bayesian estimation (via Metropolis-Hastings MCMC):\n\n\n\nVariable\nMLE Estimate\nBayesian Mean\n\n\n\n\nbrand_H\n-0.941\n-0.988\n\n\nbrand_P\n-0.440\n-0.495\n\n\nad_Yes\n-0.732\n-0.676\n\n\nprice\n-0.099\n-0.097\n\n\n\n\nInterpretation\n\nThe estimates are highly consistent across the two methods. This suggests the data is informative enough that both MLE and Bayesian approaches converge to similar values.\nThe Bayesian method adds the benefit of capturing uncertainty in the form of posterior distributions (not just point estimates).\nMinor differences in coefficients reflect the influence of the Normal(0, 1) priors used in the Bayesian approach.\nDespite a low MCMC acceptance rate, the Bayesian estimates remain stable and interpretable.\n\nBoth methods indicate that: - Consumers prefer brand N over brands H and P. - Advertising (as presented) may have a small negative effect. - Higher prices reduce the likelihood of selection.\nThis agreement supports confidence in our model‚Äôs robustness."
  },
  {
    "objectID": "homework 3.html#conclusions-and-recommendations",
    "href": "homework 3.html#conclusions-and-recommendations",
    "title": "Multinomial Logit Model",
    "section": "6. Conclusions and Recommendations",
    "text": "6. Conclusions and Recommendations\nThis project used both Maximum Likelihood Estimation (MLE) and Bayesian methods to estimate a Multinomial Logit model on simulated conjoint data. The model captured how product attributes ‚Äî including brand, advertising, and price ‚Äî influence consumer choice.\n\nKey Findings:\n\nBrand preference: Brand N is clearly the most preferred option, while brand H is the least favored. This suggests brand equity is strong for N and relatively weak for H.\nAdvertising effect: Surprisingly, advertising was associated with a negative utility. This may indicate ineffective messaging, ad fatigue, or poor targeting. Further testing (e.g., A/B testing different ad creatives) is recommended.\nPrice sensitivity: As expected, higher prices reduce the probability of choice. The estimated price coefficient can be used to simulate price elasticity and optimize pricing strategy.\n\n\n\nRecommendations:\n\nReallocate marketing spend away from brand H and toward better-performing brands like N, unless brand H is being repositioned or tested.\nRedesign advertising strategy, focusing on ad content, frequency, and targeting. Since ads currently reduce utility, improving creative quality or better segmentation could reverse this effect.\nLeverage the model for simulation ‚Äî use the estimated utilities to simulate market shares under new pricing or promotional strategies.\nConsider Bayesian modeling in future analyses when quantifying uncertainty is critical ‚Äî especially in A/B testing or market simulations.\n\n\n\nFinal Note:\nThe close agreement between MLE and Bayesian estimates reinforces the stability and robustness of the model. Conjoint analysis, paired with rigorous statistical modeling, offers powerful insights into consumer decision-making and can guide data-driven marketing strategies."
  }
]